{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1d3306",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594681b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48250154",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from struct2seq.rna_features import RNAFeatures, PositionalEncodings\n",
    "from struct2seq.rna_struct2seq import RNAStruct2Seq\n",
    "from struct2seq import noam_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfc7e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_nll(S, log_probs, mask):\n",
    "    \"\"\" Negative log probabilities \"\"\"\n",
    "    criterion = torch.nn.NLLLoss(reduction='none')\n",
    "    loss = criterion(\n",
    "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
    "    ).view(S.size())\n",
    "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
    "    return loss, loss_av\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_smoothed(S, log_probs, mask, weight=0.1, vocab_size=6):\n",
    "    \"\"\" Negative log probabilities \"\"\"\n",
    "    S_onehot = torch.nn.functional.one_hot(S, num_classes=vocab_size).float()\n",
    "\n",
    "    # Label smoothing\n",
    "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
    "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
    "\n",
    "    loss = -(S_onehot * log_probs).sum(-1)\n",
    "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
    "    return loss, loss_av\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f07d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "basedir = Path('.').resolve()\n",
    "processed_dir = basedir / 'data/rna/processed_for_ml'\n",
    "\n",
    "\n",
    "dist_map = torch.tensor(np.load(processed_dir / 'distance_map.npy'), device='cpu')\n",
    "X_train = torch.load(processed_dir / 'train.pt')\n",
    "X_val = torch.load(processed_dir / 'val.pt')\n",
    "\n",
    "train_dl = DataLoader(TensorDataset(X_train), batch_size=10)\n",
    "val_dl = DataLoader(TensorDataset(X_val), batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "747ea623",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters -- partially based on Ingraham \n",
    "vocab_size = 6\n",
    "num_node_feats = 64\n",
    "num_edge_feats = 64\n",
    "hidden_dim = 64\n",
    "num_encoder_layers = 1\n",
    "num_decoder_layers = 3\n",
    "\n",
    "smoothing_weight = 0.1\n",
    "\n",
    "\n",
    "k_nbrs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "model = RNAStruct2Seq(vocab_size, num_node_feats, num_edge_feats, dist_map, hidden_dim, num_encoder_layers, num_decoder_layers, k_nbrs)\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 2\n",
    "optimizer = noam_opt.get_std_opt(model.parameters(), hidden_dim)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.NLLLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26482053",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log files\n",
    "log_folder = basedir / 'log' / 'test_rna'\n",
    "log_folder.mkdir(exist_ok=True)\n",
    "\n",
    "logfile = log_folder / 'log.txt'\n",
    "with open(logfile, 'w') as f:\n",
    "    f.write('Epoch\\tTrain\\tValidation\\n')\n",
    "\n",
    "start_train = time.time()\n",
    "epoch_losses_train, epoch_losses_valid = [], []\n",
    "epoch_checkpoints = []\n",
    "total_step = 0\n",
    "num_epochs=10\n",
    "for e in range(num_epochs):\n",
    "    # Training epoch\n",
    "    model.train()\n",
    "    train_sum, train_weights = 0., 0.\n",
    "    for train_i, S in tqdm(enumerate(train_dl), total=len(train_dl)):\n",
    "        S = S[0].to(device)\n",
    "        \n",
    "        mask = torch.ones_like(S)\n",
    "        start_batch = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model(S)\n",
    "        _, loss_av_smoothed = loss_smoothed(S, log_probs, mask, weight=smoothing_weight)\n",
    "        loss_av_smoothed.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss, loss_av = loss_nll(S, log_probs, mask)\n",
    "\n",
    "        # Timing\n",
    "        elapsed_batch = time.time() - start_batch\n",
    "        elapsed_train = time.time() - start_train\n",
    "        total_step += 1\n",
    "        #print(total_step, elapsed_train, np.exp(loss_av.cpu().data.numpy()), np.exp(loss_av_smoothed.cpu().data.numpy()))\n",
    "\n",
    "\n",
    "        # Accumulate true loss\n",
    "        train_sum += torch.sum(loss * mask).cpu().data.numpy()\n",
    "        train_weights += torch.sum(mask).cpu().data.numpy()\n",
    "    print(f\"Train Loss: {train_sum / train_weights:.3f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_sum = 0.0 \n",
    "        val_weights = 0.0 \n",
    "        model.eval()\n",
    "        for val_i, S in tqdm(enumerate(val_dl), total=len(val_dl)):\n",
    "            S = S[0].to(device)\n",
    "            mask = torch.ones_like(S)\n",
    "            log_probs = model(S)\n",
    "            loss, loss_av = loss_nll(S, log_probs, mask)\n",
    "            val_sum += torch.sum(loss * mask).item()\n",
    "            val_weights += torch.sum(mask).item()\n",
    "    print(f\"Val Loss: {val_sum / val_weights:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/data/mambaforge/envs/pytorch_hunter/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "name": "02_RNA_Model_Training.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
